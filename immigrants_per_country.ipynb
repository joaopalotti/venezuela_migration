{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:27:22.654192Z",
     "start_time": "2018-11-14T05:27:21.899470Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import ast\n",
    "import datetime\n",
    "from misc import display, convert_unixtime, convert_country_code, cut, copy_rename, get_slice, calculate_percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:27:51.917138Z",
     "start_time": "2018-11-14T05:27:51.770220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection made on 12-11\n"
     ]
    }
   ],
   "source": [
    "#infile = \"collections/immigrants_global/dataframe_collected_finished_1537157689.csv.gz\"\n",
    "#infile = \"collections/immigrants_global/dataframe_collected_finished_1537285977.csv.gz\"\n",
    "# ... missed some...\n",
    "#infile = \"collections/immigrants_global/dataframe_collected_finished_1537764161.csv.gz\"\n",
    "\n",
    "#infile = \"collections/immigrants/dataframe_collected_finished_1537725217.csv.gz\"\n",
    "# ... missed some...\n",
    "#infile = \"collections/immigrants/dataframe_collected_finished_1538749138.csv.gz\"\n",
    "# ... missed some...\n",
    "#infile = \"collections/immigrants/dataframe_collected_finished_1539857988.csv.gz\"\n",
    "# ... missed some...\n",
    "#infile = \"collections/immigrants/dataframe_collected_finished_1539857988.csv.gz\"\n",
    "#infile = \"collections/immigrants/dataframe_collected_finished_1541491288.csv.gz\"\n",
    "#infile = \"collections/immigrants/dataframe_collected_finished_1541590184.csv.gz\"\n",
    "infile = \"collections/immigrants/dataframe_collected_finished_1542039176.csv.gz\"\n",
    "\n",
    "df = pd.read_csv(infile)\n",
    "\n",
    "#syrians = \"collections/syrians/dataframe_collected_finished_1537176338.csv.gz\"\n",
    "#syrians = \"collections/syrians/dataframe_collected_finished_1537343532.csv.gz\"\n",
    "#syrians = \"collections/syrians/dataframe_collected_finished_1537345011.csv.gz\"\n",
    "# ... missied some...\n",
    "#syrians = \"collections/syrians/dataframe_collected_finished_1537783123.csv.gz\"\n",
    "#sdf = pd.read_csv(syrians)\n",
    "#df = pd.concat((sdf,df))\n",
    "\n",
    "day, month = df[\"timestamp\"].apply(lambda x: convert_unixtime(x)).head(1).values[0].split(\"-\")\n",
    "print(\"Collection made on %s-%s\" % (day, month))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:27:56.040638Z",
     "start_time": "2018-11-14T05:27:52.982207Z"
    },
    "code_folding": [
     10,
     22,
     31,
     46,
     75,
     82,
     86,
     89
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating Group information...\n",
      "Removing redundant cols\n",
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "def extract_relationship(d):\n",
    "    if 1 in d:\n",
    "        return \"single\"\n",
    "    elif 2 in d:\n",
    "        return \"dating\"\n",
    "    elif 3 in d:\n",
    "        return \"married\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_education(d):\n",
    "    if d == [3, 7, 8, 9, 11]:\n",
    "        return \"graduated\"\n",
    "    elif d == [1, 12, 13]:\n",
    "        return \"no_degree\"\n",
    "    elif d == [2, 4, 5, 6, 10]:\n",
    "        return \"high_school\"\n",
    "    elif d == [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]:\n",
    "        return \"all\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def extract_group(d):\n",
    "    id = d[0][\"id\"]\n",
    "    if id == 6026404871583:\n",
    "        return \"Expats (Venezuela)\"\n",
    "    elif id == 6015559470583:\n",
    "        return \"Ex-pats (All)\"\n",
    "    else:\n",
    "        return \"All\"\n",
    "\n",
    "def agebuckets(minage, maxage):\n",
    "    if minage == 13 and (maxage is None or np.isnan(maxage)):\n",
    "        return \"all\"\n",
    "    elif minage == 13 and maxage == 18:\n",
    "        return \"adolecent\"\n",
    "    elif minage == 19 and maxage == 25:\n",
    "        return \"young_adult\"\n",
    "    elif minage == 26 and maxage == 40:\n",
    "        return \"adult\"\n",
    "    elif minage == 41 and maxage == 65:\n",
    "        return \"middle_age\"\n",
    "    elif minage == 65 and (maxage is None or np.isnan(maxage)):\n",
    "        return \"elder\"\n",
    "    return \"undefined\"\n",
    "    \n",
    "def expand(row):\n",
    "    place = None\n",
    "    loc_dimension = None\n",
    "    if \"regions\" in row[\"geo_locations\"]:\n",
    "        place = \"%s, %s\" % (row[\"geo_locations\"][\"regions\"][0][\"name\"], convert_country_code(row[\"geo_locations\"][\"regions\"][0][\"country_code\"]))\n",
    "        loc_dimension = \"State\"\n",
    "    elif \"countries\" in row[\"geo_locations\"]:\n",
    "        place = convert_country_code(row[\"geo_locations\"][\"countries\"][0])\n",
    "        loc_dimension = \"Country\"\n",
    "    elif \"cities\" in row[\"geo_locations\"]:\n",
    "        place = \"%s, %s, %s\" % (row[\"geo_locations\"][\"cities\"][0][\"name\"], row[\"geo_locations\"][\"cities\"][0][\"region\"], convert_country_code(row[\"geo_locations\"][\"cities\"][0][\"country\"]))\n",
    "        loc_dimension = \"City\"\n",
    "    \n",
    "    loctype = \"_\".join(row[\"geo_locations\"][\"location_types\"])\n",
    "\n",
    "    relationship, education, group = None, None, None\n",
    "    for dimension in row[\"flexible_spec\"]:\n",
    "        if \"relationship_statuses\" in dimension:\n",
    "            relationship = extract_relationship(dimension[\"relationship_statuses\"])\n",
    "        elif \"education_statuses\" in dimension:\n",
    "            education = extract_education(dimension[\"education_statuses\"])\n",
    "        elif \"behaviors\" in dimension:\n",
    "            group = extract_group(dimension[\"behaviors\"])\n",
    "    \n",
    "    gender = row[\"genders\"][0]\n",
    "    gender = \"both\" if gender == 0 else \"man\" if gender == 1 else \"woman\"\n",
    "    \n",
    "    return row[\"age_min\"], row[\"age_max\"], place, loc_dimension, loctype, gender, relationship, education, group\n",
    "\n",
    "def get_item(x):\n",
    "    if not x:\n",
    "        return None\n",
    "    return x[\"name\"]\n",
    "\n",
    "df[[\"MinAge\",\"MaxAge\",\"Location\",\"LocationHierarchy\",\"LocationType\",\"Gender\",\"Relationship\",\"Education\",\"Group\"]] = df[\"targeting\"].apply(lambda x : expand(ast.literal_eval(x))).apply(pd.Series)\n",
    "\n",
    "if \"citizenship\" in df:\n",
    "    df[\"Group\"] = df[\"citizenship\"].fillna(\"[]\").apply(lambda x : get_item(ast.literal_eval(x)))\n",
    "    print(\"Updating Group information...\")\n",
    "    \n",
    "if \"access_device\" in df:\n",
    "    df[\"Device\"] = df[\"access_device\"].fillna(\"[]\").apply(lambda x : get_item(ast.literal_eval(x)))\n",
    "    print(\"Adding information regarding devices...\")\n",
    "else:\n",
    "    df[\"Device\"] = None\n",
    "    \n",
    "df[\"AgeBucket\"] = df[[\"MinAge\",\"MaxAge\"]].apply(lambda x: agebuckets(x[\"MinAge\"], x[\"MaxAge\"]), axis=1)\n",
    "\n",
    "print(\"Removing redundant cols\")\n",
    "for col in [\"Unnamed: 0\", \"all_fields\", \"targeting\",'behavior', 'citizenship', \"mock_response\", \"access_device\", \n",
    "            \"ages_ranges\", \"household_composition\", 'interests', 'family_statuses', 'genders', 'geo_locations', 'languages',\n",
    "            'name', 'relationship_statuses', 'response', 'scholarities', 'timestamp', 'publisher_platforms',]:\n",
    "    if col in df.keys():\n",
    "        del df[col]\n",
    "\n",
    "# Gave up using travel_in   \n",
    "df = df[df[\"LocationType\"] != \"travel_in\"]\n",
    "\n",
    "print(\"All Done!\")\n",
    "# Brief description: \n",
    "# -----------------\n",
    "# Gender: 0 Both, 1 Man, 2 Woman\n",
    "# Age: 13-Null, 13-18, 19-25, 26-40, 41-65, 65+\n",
    "# LocationType: home_recent, home, recent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:27:56.393136Z",
     "start_time": "2018-11-14T05:27:56.232950Z"
    }
   },
   "outputs": [],
   "source": [
    "dfgender = {}\n",
    "dfcut = df[(df[\"Gender\"].apply(lambda x : x in [\"man\",\"woman\"])) & (df[\"Education\"].isnull()) & (df[\"Device\"].isnull()) & (df[\"AgeBucket\"] == \"all\") & (df[\"Group\"] == \"Expats (Venezuela)\") & (df[\"LocationType\"] == \"home_recent\")].copy()\n",
    "dfgender[\"mau\"] = get_slice(dfcut, \"Gender\", [\"man\",\"woman\"], frequency=\"mau\")\n",
    "dfgender[\"dau\"] = get_slice(dfcut, \"Gender\", [\"man\",\"woman\"], frequency=\"dau\")\n",
    "calculate_percentages(dfgender[\"mau\"], [\"man\",\"woman\"], \"%\")\n",
    "calculate_percentages(dfgender[\"dau\"], [\"man\",\"woman\"], \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:27:56.822796Z",
     "start_time": "2018-11-14T05:27:56.591279Z"
    }
   },
   "outputs": [],
   "source": [
    "df_gender_locals = {}\n",
    "dfcut = df[(df[\"Gender\"].apply(lambda x : x in [\"man\",\"woman\"])) & (df[\"Education\"].isnull()) & (df[\"Device\"].isnull()) \n",
    "           & (df[\"AgeBucket\"] == \"all\") & (df[\"Group\"].isnull()) & (df[\"LocationType\"] == \"home_recent\") ].copy()\n",
    "\n",
    "df_gender_locals[\"mau\"] = get_slice(dfcut, \"Gender\", [\"man\",\"woman\"], frequency=\"mau\") \n",
    "df_gender_locals[\"dau\"] = get_slice(dfcut, \"Gender\", [\"man\",\"woman\"], frequency=\"dau\")\n",
    "\n",
    "calculate_percentages(df_gender_locals[\"mau\"], [\"man\",\"woman\"], \"%locals_\")\n",
    "calculate_percentages(df_gender_locals[\"dau\"], [\"man\",\"woman\"], \"%locals_\")\n",
    "\n",
    "for col in [\"man\",\"woman\"]:\n",
    "    del df_gender_locals[\"mau\"][\"audience_\" + col]\n",
    "    del df_gender_locals[\"dau\"][\"audience_\" + col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:27:57.025953Z",
     "start_time": "2018-11-14T05:27:56.998342Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_top_going_to_aux(n, df, group):\n",
    "    \n",
    "    colname = 'audience_Expats (' + group + ')'\n",
    "    \n",
    "    if colname in df:\n",
    "        idx = df[colname].nlargest(n).index\n",
    "        locations = df.iloc[idx][[\"Location\"]].T\n",
    "        values = df.iloc[idx][[colname]].T\n",
    "    else:\n",
    "        locations = pd.DataFrame(['-'] * nlargest, index=range(1, nlargest+1)).T\n",
    "        values = pd.DataFrame(['-'] * nlargest, index=range(1, nlargest+1)).T\n",
    "\n",
    "    locations.index = [group]\n",
    "    values.index = [group]\n",
    "    return locations, values\n",
    "\n",
    "def get_top_going_to(n, df):\n",
    "    acc_loc, acc_val = [], []\n",
    "    for loc in  df_immi_place[\"mau\"][\"Location\"]:\n",
    "        toAppend_loc, toAppend_val = get_top_going_to_aux(nlargest, df, loc)\n",
    "        toAppend_loc.columns = ['goingTo{}'.format(i) for i in range(1, nlargest+1)]\n",
    "        toAppend_val.columns = ['goingTo{}_value'.format(i) for i in range(1, nlargest+1)]\n",
    "        \n",
    "        \n",
    "        acc_loc.append(toAppend_loc)\n",
    "        acc_val.append(toAppend_val)\n",
    "\n",
    "    \n",
    "    toAppend_val = pd.concat(acc_val)\n",
    "    toAppend_loc = pd.concat(acc_loc)\n",
    "    return toAppend_val, toAppend_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:00.766653Z",
     "start_time": "2018-11-14T05:27:57.191228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnlargest = 5\\n\\nfor period in [\"dau\", \"mau\"]:\\n    values, locations = get_top_going_to(nlargest, df_immi_place[period])\\n\\n    df_immi_place[period] = pd.merge(df_immi_place[period], values, left_on=[\"Location\"], right_index=True)\\n    df_immi_place[period] = pd.merge(df_immi_place[period], locations, left_on=[\"Location\"], right_index=True)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "immigrant_groups = [\"Expats (Philippines)\", \"Expats (Cuba)\", \"Expats (Ethiopia)\", \"Expats (Haiti)\", \"Expats (Spain)\", \"Expats (France)\", \"Expats (Germany)\", \"Expats (Switzerland)\", \"Expats (Hungary)\", \n",
    "                    \"Expats (United States)\", \"Expats (Ireland)\", \"Expats (Italy)\", \"Expats (Poland)\", \"Expats (Canada)\", \"Expats (China)\", \"Expats (Puerto Rico)\", \"Expats (Brazil)\", \"Expats (Indonesia)\",\n",
    "                    \"Expats (South Africa)\", \"Expats (Zimbabwe)\", \"Expats (Ghana)\", \"Expats (Uganda)\", \"Expats (Colombia)\", \"Expats (Dominican Republic)\", \"Expats (El Salvador)\", \"Expats (Guatemala)\", \n",
    "                    \"Expats (United Kingdom)\", \"Expats (Australia)\", \"Expats (Portugal)\", \"Expats (Estonia)\", \"Expats (Netherlands)\", \"Expats (Sweden)\", \"Expats (Czech Republic)\",  \"Expats (Denmark)\", \n",
    "                    \"Expats (Norway)\", \"Expats (Bangladesh)\", \"Expats (Tanzania)\", \"Expats (Nepal)\", \"Expats (Jamaica)\", \"Expats (Thailand)\", \"Expats (Sierra Leone)\", \"Expats (Senegal)\", \"Expats (Cote d'Ivore)\", \n",
    "                    \"Expats (Sri Lanka)\", \"Expats (Morocco)\", \"Expats (New Zealand)\", \"Expats (Congo Dem. Rep.)\",  \"Expats (Singapore)\", \"Expats (United Arab Emirates)\", \"Expats (Austria)\", \"Expats (Cyprus)\", \n",
    "                    \"Expats (Greece)\", \"Expats (Hong Kong)\", \"Expats (Japan)\", \"Expats (Lithuania)\", \"Expats (Luxembourg)\", \"Expats (Malta)\", \"Expats (Monaco)\", \"Expats (Slovakia)\", \"Expats (Slovenia)\", \"Expats (Mexico)\",\n",
    "                    \"Expats (Saudi Arabia)\", \"Expats (Russia)\", \"Expats (Israel)\", \"Expats (Argentina)\", \"Expats (Chile)\", \"Expats (Rwanda)\", \"Expats (Venezuela)\", \"Expats (Malaysia)\", \"Expats (Romania)\", \"Expats (South Korea)\",\n",
    "                    \"Expats (Serbia)\", \"Expats (Vietnam)\", \"Expats (Peru)\", \"Expats (Belgium)\", \"Expats (Zambia)\", \"Expats (Honduras)\", \"Expats (Finland)\", \"Expats (Latvia)\", \"Expats (Jordan)\", \"Expats (Lebanon)\",\n",
    "                    \"Expats (Nicaragua)\", \"Expats (Algeria)\", \"Expats (Kuwait)\", \"Expats (Qatar)\", \"Expats (Syria)\"\n",
    "                   ]\n",
    "\n",
    "df_immi_place = {}\n",
    "dfcut = df[(df[\"Group\"].apply(lambda x: x in immigrant_groups)) & (df[\"Gender\"] == \"both\") & (df[\"Education\"].isnull()) & \n",
    "           (df[\"Device\"].isnull()) & (df[\"AgeBucket\"] == \"all\") & (df[\"LocationType\"] == \"home_recent\")].copy()\n",
    "df_immi_place[\"mau\"] = get_slice(dfcut, \"Group\", immigrant_groups, frequency=\"mau\")\n",
    "df_immi_place[\"dau\"] = get_slice(dfcut, \"Group\", immigrant_groups, frequency=\"dau\")\n",
    "\n",
    "calculate_percentages(df_immi_place[\"mau\"], immigrant_groups, \"%\")\n",
    "calculate_percentages(df_immi_place[\"dau\"], immigrant_groups, \"%\")\n",
    "\n",
    "\"\"\"\n",
    "nlargest = 5\n",
    "\n",
    "for period in [\"dau\", \"mau\"]:\n",
    "    values, locations = get_top_going_to(nlargest, df_immi_place[period])\n",
    "\n",
    "    df_immi_place[period] = pd.merge(df_immi_place[period], values, left_on=[\"Location\"], right_index=True)\n",
    "    df_immi_place[period] = pd.merge(df_immi_place[period], locations, left_on=[\"Location\"], right_index=True)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:02.743007Z",
     "start_time": "2018-11-14T05:28:01.014410Z"
    }
   },
   "outputs": [],
   "source": [
    "# For the case of venezuela\n",
    "\n",
    "immigrant_groups = ['Expats (Venezuela)', u'Expats (United States)', u'Expats (Mexico)', u'Expats (Brazil)', u'Expats (Argentina)', \n",
    "                    u'Expats (Peru)', u'Expats (Chile)', u'Expats (Spain)', u'Expats (France)', u'Expats (United Kingdom)', u'Expats (Colombia)', \n",
    "                    u'Expats (Cuba)', u'Expats (Germany)', u'Expats (Italy)', u'Expats (Portugal)', u'Expats (Jamaica)', 'Expats (China)']\n",
    "df_immi_place = {}\n",
    "dfcut = df[(df[\"Group\"].apply(lambda x: x in immigrant_groups)) & (df[\"Gender\"] == \"both\") & (df[\"Education\"].isnull()) & \n",
    "           (df[\"Device\"].isnull()) & (df[\"AgeBucket\"] == \"all\") & (df[\"LocationType\"] == \"home_recent\")].copy()\n",
    "df_immi_place[\"mau\"] = get_slice(dfcut, \"Group\", immigrant_groups, frequency=\"mau\")\n",
    "df_immi_place[\"dau\"] = get_slice(dfcut, \"Group\", immigrant_groups, frequency=\"dau\")\n",
    "\n",
    "calculate_percentages(df_immi_place[\"mau\"], immigrant_groups, \"%\")\n",
    "calculate_percentages(df_immi_place[\"dau\"], immigrant_groups, \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:03.253873Z",
     "start_time": "2018-11-14T05:28:03.230121Z"
    }
   },
   "outputs": [],
   "source": [
    "dfcut = df[df[\"Group\"].isnull()]\n",
    "\n",
    "loc_mau = dfcut[[\"Location\", \"mau_audience\"]].rename(columns={\"mau_audience\": \"audience\"})\n",
    "loc_dau = dfcut[[\"Location\", \"dau_audience\"]].rename(columns={\"dau_audience\": \"audience\"})\n",
    "\n",
    "loc_mau[\"Frequency\"] = \"Monthly\"\n",
    "loc_dau[\"Frequency\"] = \"Daily\"\n",
    "\n",
    "df_countrypop = pd.concat((loc_mau,loc_dau))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:04.440876Z",
     "start_time": "2018-11-14T05:28:03.842573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generated dffinal\n",
    "dffinal = pd.concat([df_immi_place[\"mau\"], df_immi_place[\"dau\"]])\n",
    "dffinal = pd.merge(dffinal, df_countrypop, on=[\"Location\",\"Frequency\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:08.118436Z",
     "start_time": "2018-11-14T05:28:05.177463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add aggregated stats for total number of immigrants\n",
    "audience_group = []\n",
    "for group in immigrant_groups:\n",
    "    audience_group += [\"audience_\" + group]\n",
    "    \n",
    "dffinal[\"summary_total_immigrants\"] = dffinal[audience_group].sum(axis=1)        \n",
    "dffinal[\"immigrants_in_population\"] = (100. * dffinal[\"summary_total_immigrants\"] / dffinal[\"audience\"])\n",
    "dffinal[\"immigrants_in_population\"] = dffinal[\"immigrants_in_population\"].apply(lambda x: \"%.1f%%\" % x)\n",
    "\n",
    "dffinal[\"display_total_immigrants\"] = dffinal[\"summary_total_immigrants\"].fillna(0).apply(lambda x: display(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:14.841175Z",
     "start_time": "2018-11-14T05:28:09.541008Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "nlargest = 5\n",
    "\n",
    "for col in dffinal.keys():\n",
    "    if col.startswith(\"%\"):\n",
    "        #print(col)\n",
    "        dffinal[col] = dffinal[col].round(2)\n",
    "\n",
    "# Add TOP 'nlargest' population counts:\n",
    "audiences = [k for k in dffinal.keys() if k.startswith(\"audience_\")]\n",
    "dfaud = dffinal[audiences]\n",
    "\n",
    "def cleanCoutryName(name):\n",
    "    return \" \".join(name.rsplit()[1:]).strip(\"()\")\n",
    "\n",
    "order = np.argsort(-dfaud.values, axis=1)[:, :nlargest]\n",
    "names = pd.DataFrame(dfaud.columns[order], columns=['comeFrom{}'.format(i) for i in range(1, nlargest+1)],\n",
    "                      index=dfaud.index)\n",
    "\n",
    "for k in names.keys():\n",
    "    names[k] = names[k].apply(lambda x: cleanCoutryName(x))\n",
    "\n",
    "values = np.abs(np.sort(-dfaud.values, axis=1)[:,:nlargest])\n",
    "results = pd.DataFrame(values, columns=['comeFrom{}_value'.format(i) for i in range(1, nlargest+1)],\n",
    "                      index=dfaud.index)\n",
    "\n",
    "dffinal = pd.concat((dffinal, names, results), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-14T05:28:56.119736Z",
     "start_time": "2018-11-14T05:28:15.580209Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved immigrants_11_12.csv\n"
     ]
    }
   ],
   "source": [
    "#dffinal.to_csv(\"global_%s_%s.csv\" % (month, day), index=False)\n",
    "dffinal.to_csv(\"immigrants_%s_%s.csv\" % (month, day), index=False)\n",
    "print(\"Saved immigrants_%s_%s.csv\" % (month, day))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
